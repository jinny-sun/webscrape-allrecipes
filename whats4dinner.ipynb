{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multireplace(string, replacements, ignore_case=False):\n",
    "    \"\"\"\n",
    "    Given a string and a replacement map, it returns the replaced string.\n",
    "    :param str string: string to execute replacements on\n",
    "    :param dict replacements: replacement dictionary {value to find: value to replace}\n",
    "    :param bool ignore_case: whether the match should be case insensitive\n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    # If case insensitive, we need to normalize the old string so that later a replacement\n",
    "    # can be found. For instance with {\"HEY\": \"lol\"} we should match and find a replacement for \"hey\",\n",
    "    # \"HEY\", \"hEy\", etc.\n",
    "    if ignore_case:\n",
    "        def normalize_old(s):\n",
    "            return s.lower()\n",
    "\n",
    "        re_mode = re.IGNORECASE\n",
    "\n",
    "    else:\n",
    "        def normalize_old(s):\n",
    "            return s\n",
    "\n",
    "        re_mode = 0\n",
    "\n",
    "    replacements = {normalize_old(key): val for key, val in replacements.items()}\n",
    "    \n",
    "    # Place longer ones first to keep shorter substrings from matching where the longer ones should take place\n",
    "    # For instance given the replacements {'ab': 'AB', 'abc': 'ABC'} against the string 'hey abc', it should produce\n",
    "    # 'hey ABC' and not 'hey ABc'\n",
    "    rep_sorted = sorted(replacements, key=len, reverse=True)\n",
    "    rep_escaped = map(re.escape, rep_sorted)\n",
    "    \n",
    "    # Create a big OR regex that matches any of the substrings to replace\n",
    "    pattern = re.compile(\"|\".join(rep_escaped), re_mode)\n",
    "    \n",
    "    # For each match, look up the new string in the replacements, being the key the normalized old string\n",
    "    return pattern.sub(lambda match: replacements[normalize_old(match.group(0))], string)\n",
    "\n",
    "def string_replace(x):\n",
    "    new_string = re.sub(' {2,}', ' ', x).replace(\"\\n\", \";\").replace(\"; ;\", \";\")\n",
    "#    new_string = new_string.split(';')\n",
    "    return(new_string)\n",
    "\n",
    "def get_ingredients (x):\n",
    "    ing_regex = ('(\\d+/*\\d*\\s*\\d*/*\\d*)\\s(\\w+\\s*.*?);')\n",
    "    all_ing = re.findall(ing_regex, x)\n",
    "    return(all_ing)\n",
    "\n",
    "# def amt_ingredients(x):\n",
    "#     amt_regex = ('(\\d+/*\\d*\\s*\\d*/*\\d*).*?;')\n",
    "#     amt_ing = re.findall(amt_regex, x)\n",
    "#     return(amt_ing)\n",
    "\n",
    "def num_ingredients(x):\n",
    "    return(len(x))\n",
    "\n",
    "def get_quantity(x):\n",
    "    quantity = [y[0] for y in x] # use for df\n",
    "    units_with_ingredient = [y[1] for y in x]\n",
    "    df_of_units = pd.DataFrame({'ingredient':units_with_ingredient, 'quantity':quantity})\n",
    "    return (df_of_units)\n",
    "\n",
    "### MAY NOT NEED THIS ANYMORE ###\n",
    "def get_units(x):\n",
    "    quantity = [y[0] for y in x] # use for df\n",
    "    units_with_ingredient = [y[1] for y in x]\n",
    "    list_of_units = [re.findall(\"(\\w+)\\s*(.*)\", x)[0] for x in units_with_ingredient]\n",
    "    df_of_units = pd.DataFrame(list_of_units, columns = ['unit', 'ingredient'])\n",
    "    df_of_units['quantity'] = quantity\n",
    "    return (df_of_units)\n",
    "### MAY NOT NEED THIS ANYMORE ###\n",
    "\n",
    "def match_uids(originaldf, longdf):\n",
    "    for row in range(0, len(originaldf)):\n",
    "        longdf[row]['recipe_key']=originaldf['recipe_key'][row]\n",
    "        longdf[row]['calPerServing']=originaldf['calPerServing'][row]\n",
    "        longdf[row]['num_ingredients']=originaldf['num_ingredients'][row]\n",
    "        longdf[row]['servings']=originaldf['servings'][row]\n",
    "        longdf[row]['name']=originaldf['name'][row]\n",
    "    return(longdf)\n",
    "\n",
    "def convert_fractions (quantity):\n",
    "    from fractions import Fraction\n",
    "    return float(sum(Fraction(s) for s in quantity.split()))\n",
    "\n",
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    import string\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    def lemmatize(string):\n",
    "        for word in re.findall(r\"[a-z]+\", string):\n",
    "            string = string.replace(word, wnl.lemmatize(word, 'n') if 's' in word[-3:] else word)\n",
    "        return string\n",
    "\n",
    "    # Remove anything in parenthesis\n",
    "    mess = re.sub(r\"\\([^\\)]+\\)\", '', mess)\n",
    "    \n",
    "    # Make everything lowercase\n",
    "    mess = mess.lower()\n",
    "    # Remove non-word punctuation\n",
    "    mess =' '.join(re.findall(r\"[-,''\\w]+\", mess)) # This leaves some commas as a character #\n",
    "    mess = re.sub(r\"\\,\", ' ', mess)\n",
    "    # Remove punctuation and numbers\n",
    "    #mess = ''.join([char for char in mess if char not in string.punctuation])\n",
    "    mess = ''.join([i for i in mess if not i.isdigit()])\n",
    "    # Remove plurals\n",
    "    mess = lemmatize(mess)\n",
    "    #clean excess whitespace\n",
    "    mess = re.sub(r\"\\s+\", ' ', mess).strip()\n",
    "    # Remove stopwords\n",
    "    return([word for word in mess.split() if word.lower() not in stopwords.words('english')])\n",
    "\n",
    "def unit_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    import string\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    def lemmatize(string):\n",
    "        for word in re.findall(r\"[a-z]+\", string):\n",
    "            string = string.replace(word, wnl.lemmatize(word, 'n') if 's' in word[-3:] else word)\n",
    "        return string\n",
    "\n",
    "    # Remove anything in parenthesis\n",
    "    mess = re.sub(r\"\\([^\\)]+\\)\", '', mess)\n",
    "    \n",
    "    # Make everything lowercase\n",
    "    mess = mess.lower()\n",
    "    # Remove non-word punctuation\n",
    "    mess =' '.join(re.findall(r\"[-,''\\w]+\", mess)) # This leaves some commas as a character #\n",
    "    mess = re.sub(r\"\\,\", ' ', mess)\n",
    "    # Remove punctuation and numbers\n",
    "    #mess = ''.join([char for char in mess if char not in string.punctuation])\n",
    "    mess = ''.join([i for i in mess if not i.isdigit()])\n",
    "    # Remove plurals\n",
    "    mess = lemmatize(mess)\n",
    "    #clean excess whitespace\n",
    "    mess = re.sub(r\"\\s+\", ' ', mess).strip()\n",
    "    # Remove stopwords\n",
    "    mess = [word for word in mess.split() if word.lower() not in stopwords.words('english')]\n",
    "    if len(mess)>=1:\n",
    "        return(mess[0])\n",
    "    else:\n",
    "        return('unit')\n",
    "\n",
    "def unit_to_integer(mess):\n",
    "    # Keep integers\n",
    "    mess = ''.join([i for i in mess if  i.isdigit()])\n",
    "\n",
    "    if len(mess)>=1:\n",
    "        return(mess)\n",
    "    else:\n",
    "        return('1')\n",
    "\n",
    "def join_strings(mess):\n",
    "    # Keep integers\n",
    "    mess = ' '.join(mess)\n",
    "\n",
    "    if len(mess)>=1:\n",
    "        return(mess)\n",
    "    else:\n",
    "        return('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('dataset_allrecipes-test-v3_2020-06-02_01-37-25-797.csv')\n",
    "\n",
    "# Clean column names\n",
    "df.rename(columns = {'calories':'calPerServing', 'cook':'cookTime', 'prep':'prepTime','ready in':'totalTime'}, inplace = True) \n",
    "\n",
    "# Create unique id\n",
    "df['recipe_key'] = df['url'].apply(lambda x:int(re.findall(r\"\\d+\", x)[0]))\n",
    "\n",
    "# Remove null values and reset index\n",
    "df.dropna(axis=0, how='any',inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Clean ingredient text\n",
    "dict_unicode = {'\\u2009': '', '½':' 1/2', '⅓':'1/3', '⅔':'2/3', '¼':'1/4', '¾':'3/4', '⅕':'1/5', \n",
    "                '⅖':'2/5', '⅗':'3/5', '⅘':'4/5', '⅙':'1/6', '⅚':'5/6', '⅐':'1/7', '⅛':'1/8', \n",
    "                '⅜':'3/8', '⅝':'5/8', '⅞':'7/8', '⅑':'1/9', '⅒':'1/10'}\n",
    "df['recipeIngredient'] = [item + ';' for item in df['recipeIngredient']] # add semicolon at end of each string for easier regex filtering\n",
    "df['recipeIngredient'] = [multireplace(x, dict_unicode) for x in df['recipeIngredient']] # replace unicode characters\n",
    "df['recipeIngredient'] = [string_replace(x) for x in df['recipeIngredient']] # remove whitespace\n",
    "ing = [get_ingredients(x) for x in df['recipeIngredient']] # separate ingredients into list of list of tupules of ingredient strings\n",
    "df['num_ingredients'] = [len(x) for x in ing] # count number of ingredients per recipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new version of df_ing with get_quantity(x)\n",
    "#df_ing = [get_quantity(x) for x in ing] # separate units of measure and ingredients & creates a pandas dataframe for each recipe\n",
    "\n",
    "# original version\n",
    "df_ing = [get_units(x) for x in ing] # separate units of measure and ingredients & creates a pandas dataframe for each recipe\n",
    "\n",
    "clean_df = match_uids(df, df_ing) # pull unique id, calorie (outcome variable), number of servings, and number of ingredients from original dataframe\n",
    "clean_df = pd.concat(clean_df) # concat list of pandas dataframes into one dataframe\n",
    "clean_df['quantity'] = [convert_fractions(x) for x in clean_df['quantity']] # convert fractions into integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiIndex / hierarchical Dataframe\n",
    "clean_df = clean_df.reset_index()\n",
    "arrays = [clean_df['recipe_key'],clean_df['index']]\n",
    "tuples = tuples = list(zip(*arrays))\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['recipe_key', 'ingredient_key'])\n",
    "clean_df.set_index(index,inplace=True)\n",
    "#clean_df['ingredient'].replace('',clean_df['unit'],inplace=True)\n",
    "clean_df.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ingredient</th>\n",
       "      <th>quantity</th>\n",
       "      <th>recipe_key</th>\n",
       "      <th>calPerServing</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>servings</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recipe_key</th>\n",
       "      <th>ingredient_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">229099</th>\n",
       "      <th>0</th>\n",
       "      <td>cup crushed corn flakes</td>\n",
       "      <td>0.75</td>\n",
       "      <td>229099</td>\n",
       "      <td>277.7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>Breaded Parmesan Ranch Chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cup grated Parmesan cheese</td>\n",
       "      <td>0.75</td>\n",
       "      <td>229099</td>\n",
       "      <td>277.7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>Breaded Parmesan Ranch Chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ounce) envelope ranch salad dressing mix</td>\n",
       "      <td>1.00</td>\n",
       "      <td>229099</td>\n",
       "      <td>277.7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>Breaded Parmesan Ranch Chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ounce) skinless, boneless chicken breast halves</td>\n",
       "      <td>4.00</td>\n",
       "      <td>229099</td>\n",
       "      <td>277.7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>Breaded Parmesan Ranch Chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cup butter, melted</td>\n",
       "      <td>0.50</td>\n",
       "      <td>229099</td>\n",
       "      <td>277.7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>Breaded Parmesan Ranch Chicken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                ingredient  \\\n",
       "recipe_key ingredient_key                                                    \n",
       "229099     0                                       cup crushed corn flakes   \n",
       "           1                                    cup grated Parmesan cheese   \n",
       "           2                      ounce) envelope ranch salad dressing mix   \n",
       "           3               ounce) skinless, boneless chicken breast halves   \n",
       "           4                                            cup butter, melted   \n",
       "\n",
       "                           quantity  recipe_key  calPerServing  \\\n",
       "recipe_key ingredient_key                                        \n",
       "229099     0                   0.75      229099          277.7   \n",
       "           1                   0.75      229099          277.7   \n",
       "           2                   1.00      229099          277.7   \n",
       "           3                   4.00      229099          277.7   \n",
       "           4                   0.50      229099          277.7   \n",
       "\n",
       "                           num_ingredients  servings  \\\n",
       "recipe_key ingredient_key                              \n",
       "229099     0                             5         8   \n",
       "           1                             5         8   \n",
       "           2                             5         8   \n",
       "           3                             5         8   \n",
       "           4                             5         8   \n",
       "\n",
       "                                                     name  \n",
       "recipe_key ingredient_key                                  \n",
       "229099     0               Breaded Parmesan Ranch Chicken  \n",
       "           1               Breaded Parmesan Ranch Chicken  \n",
       "           2               Breaded Parmesan Ranch Chicken  \n",
       "           3               Breaded Parmesan Ranch Chicken  \n",
       "           4               Breaded Parmesan Ranch Chicken  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv for web app\n",
    "clean_df.to_csv('clean_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For use with new version of df_ing with get_quantity(x)\n",
    "\n",
    "# def remove_units(words):\n",
    "#     stopwords = ['dash','pinch','teaspoon','fluid','cup','pint','quart','ounce','oz','pound','rack',\n",
    "#                 'small','medium','large','crushed','grated','skinless','boneless','melted','fresh',\n",
    "#                  'diced','minced','thinly','dry','dried','halved','taste','frying','lean','drained','jars','grated'\n",
    "#                 'clove','slice','eaches','whole','cube','thick','unit','freshly','finely','splash']\n",
    "#     ingredient_words = words.split()\n",
    "#     resultwords  = [word for word in ingredient_words if word.lower() not in stopwords]\n",
    "#     result = ' '.join(resultwords)\n",
    "#     return(result)\n",
    "\n",
    "# clean_df['unit'] = np.where(clean_df.ingredient.str.contains(\"dash\"), \"1/3\",\n",
    "#             np.where(clean_df.ingredient.str.contains(\"pinch\"), \"2/3\",\n",
    "#             np.where(clean_df.ingredient.str.contains(\"teaspoon\"), \"5\", \n",
    "#             np.where(clean_df.ingredient.str.contains(\"tablespoon\"), \"15\",\n",
    "#             np.where(clean_df.ingredient.str.contains(\"fluid\"), \"30\",\n",
    "#             np.where(clean_df.ingredient.str.contains(\"cup\"), \"240\", \n",
    "#             np.where(clean_df.ingredient.str.contains(\"pint\"), \"473\",\n",
    "#             np.where(clean_df.ingredient.str.contains(\"quart\"), \"950\",\n",
    "#             np.where(clean_df.ingredient.str.contains(\"ounce\"), \"28\",\n",
    "#             np.where(clean_df.ingredient.str.contains(\"oz\"), \"28\", \n",
    "#             np.where(clean_df.ingredient.str.contains(\"pound\"), \"454\",\n",
    "#             np.where(clean_df.ingredient.str.contains(\"rack\"), \"908\",\n",
    "#             \"1\"))))))))))))\n",
    "# clean_df['ingredient'] = [remove_units(x) for x in clean_df['ingredient']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization = convert text string into list of tokens, or words, we want (i.e., cleaned version of words).\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "clean_df['ingredient']=[text_process(x) for x in clean_df['ingredient']]\n",
    "# clean_df['unit']=[unit_process(x) for x in clean_df['unit']]\n",
    "\n",
    "thresh = 600; # calorie threshold; mean = 500, median = 463, 75%quartile = 600\n",
    "df['label'] = [1 if a_ > thresh else 0 for a_ in df['calPerServing']]\n",
    "clean_df['label'] = [1 if a_ > thresh else 0 for a_ in clean_df['calPerServing']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### This code needs to be fixed if using updated df_ing with get_quantity(x)\n",
    "\n",
    "# Normalize units and present as list of values per column\n",
    "dict_unit = {'dash': '1/3', 'pinch':'2/3', 'teaspoon':'5', 'tablespoon':'15', 'fluid':'30', \n",
    "                 'cup':'240', 'pint':'950', 'quart':'950', 'ounce':'28', 'oz':'28', \n",
    "                 'pound':'454','rack':'908',\n",
    "             #'small':'50', 'medium':'60', 'large':'70', 'unit':'50' # don't take this into account since some ingredients are in the unit column (ex. onion, egg)\n",
    "            }\n",
    "\n",
    "### For use with updated df_ing with get_quantity(x)\n",
    "#unit_int = clean_df['ingredient'].copy()\n",
    "\n",
    "unit_int = clean_df['unit'].copy()\n",
    "unit_int = [multireplace(x, dict_unit) for x in unit_int] # Normalize unit measurements to grams\n",
    "unit_int = [unit_to_integer(x) for x in unit_int] # convert string of values into integers\n",
    "unit_int = [convert_fractions(x) for x in unit_int] # convert fractions into integers\n",
    "unit_quantity = pd.DataFrame(unit_int * clean_df['quantity']) # Multiply grams with quantity of unit\n",
    "unit_quantity = unit_quantity.groupby('recipe_key').agg(lambda col: col.tolist()) # condense list of values to each recipe key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP\n",
    "1) Bag of words\n",
    "\n",
    "2) TF-IDF (term frequency-inverse document frequency)\n",
    "\n",
    "3) Combine word weights (from TF-IDF) with quantitative metrics (quantity, serving size), then model based on that\n",
    "\n",
    "4) Train test split\n",
    "\n",
    "5) Machine learning model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set contains 688 reviews in total\n",
      "Test set contains 173 reviews in total\n"
     ]
    }
   ],
   "source": [
    "# Original working version\n",
    "df.rename(columns = {'recipe_key':'key'}, inplace = True) \n",
    "clean_df.rename(columns = {'recipe_key':'key'}, inplace = True) \n",
    "X_ing = clean_df[['ingredient', 'key']].groupby('key').agg(sum) # # condense list of ingredients to each recipe key\n",
    "X_ing['clean_ing'] = [join_strings(x) for x in X_ing['ingredient']] # joins list of strings into one string per recipe\n",
    "\n",
    "df['totalCal'] = df['calPerServing']*df['servings']\n",
    "y_cal = df.set_index('key')[['totalCal','calPerServing','name','label']].copy()\n",
    "\n",
    "y_label = df.reset_index(drop=True)['label']\n",
    "X_keys = df.reset_index(drop=True)['key']\n",
    "\n",
    "from sklearn.model_selection import train_test_split # Train Test Split\n",
    "key_train, key_test, y_train, y_test = train_test_split(X_keys, y_label, test_size=0.2, random_state=101) # won't work with multilevel index\n",
    "\n",
    "X_train = X_ing.loc[key_train]\n",
    "X_test = X_ing.loc[key_test]\n",
    "y_cal_train = y_cal.loc[key_train]\n",
    "y_cal_test = y_cal.loc[key_test]\n",
    "\n",
    "print(\"Training set contains {} reviews in total\".format(len(key_train)))\n",
    "print(\"Test set contains {} reviews in total\".format(len(key_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredient</th>\n",
       "      <th>clean_ing</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8495</th>\n",
       "      <td>[boneless, chicken, breast, half, salt, ground...</td>\n",
       "      <td>boneless chicken breast half salt ground black...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216758</th>\n",
       "      <td>[butter, onion, chopped, rib, chopped, chopped...</td>\n",
       "      <td>butter onion chopped rib chopped chopped froze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17143</th>\n",
       "      <td>[coarse, kosher, salt, prime, rib, roast, grou...</td>\n",
       "      <td>coarse kosher salt prime rib roast ground blac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22729</th>\n",
       "      <td>[noodle, olive, oil, chopped, fresh, mushroom,...</td>\n",
       "      <td>noodle olive oil chopped fresh mushroom choppe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143458</th>\n",
       "      <td>[finely, chopped, fresh, cilantro, garlic, min...</td>\n",
       "      <td>finely chopped fresh cilantro garlic minced ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148238</th>\n",
       "      <td>[thick, cut, pork, chop, smoked, gouda, cheese...</td>\n",
       "      <td>thick cut pork chop smoked gouda cheese fresh ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21528</th>\n",
       "      <td>[pre-baked, pizza, crust, pesto, tomato, chopp...</td>\n",
       "      <td>pre-baked pizza crust pesto tomato chopped gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276690</th>\n",
       "      <td>[boneless, beef, chuck, roast, cut, -inch, thi...</td>\n",
       "      <td>boneless beef chuck roast cut -inch thick stri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229123</th>\n",
       "      <td>[ground, beef, finely, chopped, shredded, ched...</td>\n",
       "      <td>ground beef finely chopped shredded cheddar ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258878</th>\n",
       "      <td>[skin-on, bone-in, chicken, thigh, salt, groun...</td>\n",
       "      <td>skin-on bone-in chicken thigh salt ground blac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>688 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               ingredient  \\\n",
       "key                                                         \n",
       "8495    [boneless, chicken, breast, half, salt, ground...   \n",
       "216758  [butter, onion, chopped, rib, chopped, chopped...   \n",
       "17143   [coarse, kosher, salt, prime, rib, roast, grou...   \n",
       "22729   [noodle, olive, oil, chopped, fresh, mushroom,...   \n",
       "143458  [finely, chopped, fresh, cilantro, garlic, min...   \n",
       "...                                                   ...   \n",
       "148238  [thick, cut, pork, chop, smoked, gouda, cheese...   \n",
       "21528   [pre-baked, pizza, crust, pesto, tomato, chopp...   \n",
       "276690  [boneless, beef, chuck, roast, cut, -inch, thi...   \n",
       "229123  [ground, beef, finely, chopped, shredded, ched...   \n",
       "258878  [skin-on, bone-in, chicken, thigh, salt, groun...   \n",
       "\n",
       "                                                clean_ing  \n",
       "key                                                        \n",
       "8495    boneless chicken breast half salt ground black...  \n",
       "216758  butter onion chopped rib chopped chopped froze...  \n",
       "17143   coarse kosher salt prime rib roast ground blac...  \n",
       "22729   noodle olive oil chopped fresh mushroom choppe...  \n",
       "143458  finely chopped fresh cilantro garlic minced ch...  \n",
       "...                                                   ...  \n",
       "148238  thick cut pork chop smoked gouda cheese fresh ...  \n",
       "21528   pre-baked pizza crust pesto tomato chopped gre...  \n",
       "276690  boneless beef chuck roast cut -inch thick stri...  \n",
       "229123  ground beef finely chopped shredded cheddar ch...  \n",
       "258878  skin-on bone-in chicken thigh salt ground blac...  \n",
       "\n",
       "[688 rows x 2 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114    0\n",
       "209    0\n",
       "331    0\n",
       "274    0\n",
       "563    0\n",
       "      ..\n",
       "599    0\n",
       "575    0\n",
       "838    1\n",
       "337    0\n",
       "523    0\n",
       "Name: label, Length: 688, dtype: int64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totalCal</th>\n",
       "      <th>calPerServing</th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8495</th>\n",
       "      <td>1675.2</td>\n",
       "      <td>418.8</td>\n",
       "      <td>Chicken Cordon Bleu I</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216758</th>\n",
       "      <td>3464.4</td>\n",
       "      <td>577.4</td>\n",
       "      <td>Mom's Fabulous Chicken Pot Pie with Biscuit Crust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17143</th>\n",
       "      <td>2346.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>Kosher Salt Encrusted Prime Rib Roast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22729</th>\n",
       "      <td>4320.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>Spinach Lasagna III</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143458</th>\n",
       "      <td>4436.8</td>\n",
       "      <td>554.6</td>\n",
       "      <td>Amazing Southwest Cilantro Lime Mango Grilled ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148238</th>\n",
       "      <td>1804.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>Gouda and Spinach Stuffed Pork Chops</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21528</th>\n",
       "      <td>2362.2</td>\n",
       "      <td>393.7</td>\n",
       "      <td>Pesto Pizza</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276690</th>\n",
       "      <td>2432.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>Miso-Braised Beef with King Mushrooms</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229123</th>\n",
       "      <td>4665.6</td>\n",
       "      <td>583.2</td>\n",
       "      <td>Best Beef Enchiladas</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258878</th>\n",
       "      <td>1134.6</td>\n",
       "      <td>189.1</td>\n",
       "      <td>Crispy Baked Chicken Thighs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>688 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        totalCal  calPerServing  \\\n",
       "key                               \n",
       "8495      1675.2          418.8   \n",
       "216758    3464.4          577.4   \n",
       "17143     2346.0          391.0   \n",
       "22729     4320.0          360.0   \n",
       "143458    4436.8          554.6   \n",
       "...          ...            ...   \n",
       "148238    1804.0          451.0   \n",
       "21528     2362.2          393.7   \n",
       "276690    2432.0          608.0   \n",
       "229123    4665.6          583.2   \n",
       "258878    1134.6          189.1   \n",
       "\n",
       "                                                     name  label  \n",
       "key                                                               \n",
       "8495                                Chicken Cordon Bleu I      0  \n",
       "216758  Mom's Fabulous Chicken Pot Pie with Biscuit Crust      0  \n",
       "17143               Kosher Salt Encrusted Prime Rib Roast      0  \n",
       "22729                                 Spinach Lasagna III      0  \n",
       "143458  Amazing Southwest Cilantro Lime Mango Grilled ...      0  \n",
       "...                                                   ...    ...  \n",
       "148238               Gouda and Spinach Stuffed Pork Chops      0  \n",
       "21528                                         Pesto Pizza      0  \n",
       "276690              Miso-Braised Beef with King Mushrooms      1  \n",
       "229123                               Best Beef Enchiladas      0  \n",
       "258878                        Crispy Baked Chicken Thighs      0  \n",
       "\n",
       "[688 rows x 4 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cal_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For web app\n",
    "# X_ing = clean_df[['ingredient', 'name']].groupby('name').agg(sum) # # condense list of ingredients to each recipe key\n",
    "# X_ing['clean_ing'] = [join_strings(x) for x in X_ing['ingredient']] # joins list of strings into one string per recipe\n",
    "# X_ing = X_ing.head().reset_index()\n",
    "# X_ing['key'] = df.reset_index(drop=True)['key']\n",
    "# X_ing = X_ing.set_index('key',drop=True)\n",
    "\n",
    "# df['totalCal'] = df['calPerServing']*df['servings']\n",
    "# y_cal = df.set_index('key')[['totalCal','calPerServing','name']].copy()\n",
    "\n",
    "# y_label = df.reset_index(drop=True)['label']\n",
    "# X_keys = df.reset_index(drop=True)['key']\n",
    "\n",
    "# from sklearn.model_selection import train_test_split # Train Test Split\n",
    "# key_train, key_test, y_train, y_test = train_test_split(X_keys, y_label, test_size=0.2, random_state=101) # won't work with multilevel index\n",
    "\n",
    "# X_train = X_ing.loc[key_train]\n",
    "# X_test = X_ing.loc[key_test]\n",
    "# y_cal_train = y_cal.loc[key_train]\n",
    "# y_cal_test = y_cal.loc[key_test]\n",
    "\n",
    "# print(\"Training set contains {} reviews in total\".format(len(key_train)))\n",
    "# print(\"Test set contains {} reviews in total\".format(len(key_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data as csv\n",
    "X_train.to_csv('X_train.csv')\n",
    "X_test.to_csv('X_test.csv')\n",
    "y_train.to_csv('y_train.csv')\n",
    "y_test.to_csv('y_test.csv')\n",
    "y_cal_train.to_csv('y_cal_train.csv')\n",
    "y_cal_test.to_csv('y_cal_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calPerServing</th>\n",
       "      <th>carbohydratesg</th>\n",
       "      <th>cholesterolmg</th>\n",
       "      <th>cookTime</th>\n",
       "      <th>directions</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>name</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>prepTime</th>\n",
       "      <th>proteing</th>\n",
       "      <th>...</th>\n",
       "      <th>recipeDirection</th>\n",
       "      <th>recipeIngredient</th>\n",
       "      <th>servings</th>\n",
       "      <th>sodiummg</th>\n",
       "      <th>totalFatg</th>\n",
       "      <th>url</th>\n",
       "      <th>key</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>label</th>\n",
       "      <th>totalCal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>277.7</td>\n",
       "      <td>277.7 calories;           26.8 g protein;     ...</td>\n",
       "      <td>101.7</td>\n",
       "      <td>45 mins</td>\n",
       "      <td>1. Preheat oven to 350 degrees F (175 degrees ...</td>\n",
       "      <td>¾ cup crushed corn flakes, ¾ cup grated Parmes...</td>\n",
       "      <td>Breaded Parmesan Ranch Chicken</td>\n",
       "      <td>277.7 calories;           26.8 g protein;     ...</td>\n",
       "      <td>10 mins</td>\n",
       "      <td>26.8</td>\n",
       "      <td>...</td>\n",
       "      <td>Preheat oven to 350 degrees F (175 degrees C)....</td>\n",
       "      <td>3/4 cup crushed corn flakes; 3/4 cup grated Pa...</td>\n",
       "      <td>8</td>\n",
       "      <td>277.7 calories;           26.8 g protein;     ...</td>\n",
       "      <td>277.7 calories;           26.8 g protein;     ...</td>\n",
       "      <td>https://www.allrecipes.com/recipe/229099/bread...</td>\n",
       "      <td>229099</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2221.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1138.8</td>\n",
       "      <td>1138.8 calories;           80.4 g protein;    ...</td>\n",
       "      <td>283.6</td>\n",
       "      <td>50 mins</td>\n",
       "      <td>1. Preheat oven to 425 degrees F (220 degrees ...</td>\n",
       "      <td>4 pounds skin-on, bone-in chicken thighs, 1 ta...</td>\n",
       "      <td>Greek Lemon Chicken and Potatoes</td>\n",
       "      <td>1138.8 calories;           80.4 g protein;    ...</td>\n",
       "      <td>10 mins</td>\n",
       "      <td>80.4</td>\n",
       "      <td>...</td>\n",
       "      <td>Preheat oven to 425 degrees F (220 degrees C)....</td>\n",
       "      <td>4 pounds skin-on, bone-in chicken thighs; 1 ta...</td>\n",
       "      <td>4</td>\n",
       "      <td>1138.8 calories;           80.4 g protein;    ...</td>\n",
       "      <td>1138.8 calories;           80.4 g protein;    ...</td>\n",
       "      <td>https://www.allrecipes.com/recipe/242352/greek...</td>\n",
       "      <td>242352</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4555.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>524.0</td>\n",
       "      <td>524 calories;           34.5 g total fat;     ...</td>\n",
       "      <td>153.0</td>\n",
       "      <td>45 mins</td>\n",
       "      <td>1. Combine bread crumbs, onion, egg, parsley, ...</td>\n",
       "      <td>¼ cup fresh bread crumbs, ¼ cup finely diced o...</td>\n",
       "      <td>Instant Pot® Salisbury Steak with Onion and Mu...</td>\n",
       "      <td>524 calories;           34.5 g total fat;     ...</td>\n",
       "      <td>10 mins</td>\n",
       "      <td>34.5</td>\n",
       "      <td>...</td>\n",
       "      <td>Combine bread crumbs, onion, egg, parsley, Wor...</td>\n",
       "      <td>1/4 cup fresh bread crumbs; 1/4 cup finely dic...</td>\n",
       "      <td>4</td>\n",
       "      <td>524 calories;           34.5 g total fat;     ...</td>\n",
       "      <td>524 calories;           34.5 g total fat;     ...</td>\n",
       "      <td>https://www.allrecipes.com/recipe/265280/insta...</td>\n",
       "      <td>265280</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>828.8</td>\n",
       "      <td>828.8 calories;           36.4 g protein;     ...</td>\n",
       "      <td>189.3</td>\n",
       "      <td>30 mins</td>\n",
       "      <td>1. Heat the frying oil in a deep-fryer or larg...</td>\n",
       "      <td>4 cups vegetable oil for frying, 3   eggs, ½ c...</td>\n",
       "      <td>Deb's General Tso's Chicken</td>\n",
       "      <td>828.8 calories;           36.4 g protein;     ...</td>\n",
       "      <td>25 mins</td>\n",
       "      <td>36.4</td>\n",
       "      <td>...</td>\n",
       "      <td>Heat the frying oil in a deep-fryer or large s...</td>\n",
       "      <td>4 cups vegetable oil for frying; 3 eggs; 1/2 c...</td>\n",
       "      <td>6</td>\n",
       "      <td>828.8 calories;           36.4 g protein;     ...</td>\n",
       "      <td>828.8 calories;           36.4 g protein;     ...</td>\n",
       "      <td>https://www.allrecipes.com/recipe/92761/debs-g...</td>\n",
       "      <td>92761</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>4972.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>734.8</td>\n",
       "      <td>734.8 calories;           28.9 g protein;     ...</td>\n",
       "      <td>159.2</td>\n",
       "      <td>10 mins</td>\n",
       "      <td>1. Bring a large pot of lightly salted water t...</td>\n",
       "      <td>1 (16 ounce) package egg noodles, 1 pound lean...</td>\n",
       "      <td>Simple Hamburger Stroganoff</td>\n",
       "      <td>734.8 calories;           28.9 g protein;     ...</td>\n",
       "      <td>20 mins</td>\n",
       "      <td>28.9</td>\n",
       "      <td>...</td>\n",
       "      <td>Bring a large pot of lightly salted water to a...</td>\n",
       "      <td>1 (16 ounce) package egg noodles; 1 pound lean...</td>\n",
       "      <td>6</td>\n",
       "      <td>734.8 calories;           28.9 g protein;     ...</td>\n",
       "      <td>734.8 calories;           28.9 g protein;     ...</td>\n",
       "      <td>https://www.allrecipes.com/recipe/23260/simple...</td>\n",
       "      <td>23260</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4408.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   calPerServing                                     carbohydratesg  \\\n",
       "0          277.7  277.7 calories;           26.8 g protein;     ...   \n",
       "1         1138.8  1138.8 calories;           80.4 g protein;    ...   \n",
       "2          524.0  524 calories;           34.5 g total fat;     ...   \n",
       "3          828.8  828.8 calories;           36.4 g protein;     ...   \n",
       "4          734.8  734.8 calories;           28.9 g protein;     ...   \n",
       "\n",
       "   cholesterolmg cookTime                                         directions  \\\n",
       "0          101.7  45 mins  1. Preheat oven to 350 degrees F (175 degrees ...   \n",
       "1          283.6  50 mins  1. Preheat oven to 425 degrees F (220 degrees ...   \n",
       "2          153.0  45 mins  1. Combine bread crumbs, onion, egg, parsley, ...   \n",
       "3          189.3  30 mins  1. Heat the frying oil in a deep-fryer or larg...   \n",
       "4          159.2  10 mins  1. Bring a large pot of lightly salted water t...   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  ¾ cup crushed corn flakes, ¾ cup grated Parmes...   \n",
       "1  4 pounds skin-on, bone-in chicken thighs, 1 ta...   \n",
       "2  ¼ cup fresh bread crumbs, ¼ cup finely diced o...   \n",
       "3  4 cups vegetable oil for frying, 3   eggs, ½ c...   \n",
       "4  1 (16 ounce) package egg noodles, 1 pound lean...   \n",
       "\n",
       "                                                name  \\\n",
       "0                     Breaded Parmesan Ranch Chicken   \n",
       "1                   Greek Lemon Chicken and Potatoes   \n",
       "2  Instant Pot® Salisbury Steak with Onion and Mu...   \n",
       "3                        Deb's General Tso's Chicken   \n",
       "4                        Simple Hamburger Stroganoff   \n",
       "\n",
       "                                           nutrition prepTime  proteing  ...  \\\n",
       "0  277.7 calories;           26.8 g protein;     ...  10 mins      26.8  ...   \n",
       "1  1138.8 calories;           80.4 g protein;    ...  10 mins      80.4  ...   \n",
       "2  524 calories;           34.5 g total fat;     ...  10 mins      34.5  ...   \n",
       "3  828.8 calories;           36.4 g protein;     ...  25 mins      36.4  ...   \n",
       "4  734.8 calories;           28.9 g protein;     ...  20 mins      28.9  ...   \n",
       "\n",
       "                                     recipeDirection  \\\n",
       "0  Preheat oven to 350 degrees F (175 degrees C)....   \n",
       "1  Preheat oven to 425 degrees F (220 degrees C)....   \n",
       "2  Combine bread crumbs, onion, egg, parsley, Wor...   \n",
       "3  Heat the frying oil in a deep-fryer or large s...   \n",
       "4  Bring a large pot of lightly salted water to a...   \n",
       "\n",
       "                                    recipeIngredient servings  \\\n",
       "0  3/4 cup crushed corn flakes; 3/4 cup grated Pa...        8   \n",
       "1  4 pounds skin-on, bone-in chicken thighs; 1 ta...        4   \n",
       "2  1/4 cup fresh bread crumbs; 1/4 cup finely dic...        4   \n",
       "3  4 cups vegetable oil for frying; 3 eggs; 1/2 c...        6   \n",
       "4  1 (16 ounce) package egg noodles; 1 pound lean...        6   \n",
       "\n",
       "                                            sodiummg  \\\n",
       "0  277.7 calories;           26.8 g protein;     ...   \n",
       "1  1138.8 calories;           80.4 g protein;    ...   \n",
       "2  524 calories;           34.5 g total fat;     ...   \n",
       "3  828.8 calories;           36.4 g protein;     ...   \n",
       "4  734.8 calories;           28.9 g protein;     ...   \n",
       "\n",
       "                                           totalFatg  \\\n",
       "0  277.7 calories;           26.8 g protein;     ...   \n",
       "1  1138.8 calories;           80.4 g protein;    ...   \n",
       "2  524 calories;           34.5 g total fat;     ...   \n",
       "3  828.8 calories;           36.4 g protein;     ...   \n",
       "4  734.8 calories;           28.9 g protein;     ...   \n",
       "\n",
       "                                                 url     key num_ingredients  \\\n",
       "0  https://www.allrecipes.com/recipe/229099/bread...  229099               5   \n",
       "1  https://www.allrecipes.com/recipe/242352/greek...  242352              12   \n",
       "2  https://www.allrecipes.com/recipe/265280/insta...  265280              18   \n",
       "3  https://www.allrecipes.com/recipe/92761/debs-g...   92761              14   \n",
       "4  https://www.allrecipes.com/recipe/23260/simple...   23260               8   \n",
       "\n",
       "  label  totalCal  \n",
       "0     0    2221.6  \n",
       "1     1    4555.2  \n",
       "2     0    2096.0  \n",
       "3     1    4972.8  \n",
       "4     1    4408.8  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ingredient</th>\n",
       "      <th>clean_ing</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>229099</th>\n",
       "      <td>\"Instant\" Mac and Cheese</td>\n",
       "      <td>[whole, milk, kosher, salt, taste, cayenne, pe...</td>\n",
       "      <td>whole milk kosher salt taste cayenne pepper dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242352</th>\n",
       "      <td>\"Pantry Raid\" Chicken Enchilada Casserole</td>\n",
       "      <td>[tomato, sauce, water, taco, seasoning, mix, c...</td>\n",
       "      <td>tomato sauce water taco seasoning mix chili po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265280</th>\n",
       "      <td>A Scotsman's Shepherd Pie</td>\n",
       "      <td>[mashed, boiled, potato, sour, cream, cream, c...</td>\n",
       "      <td>mashed boiled potato sour cream cream cheese b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92761</th>\n",
       "      <td>Absolute Best Liver and Onions</td>\n",
       "      <td>[sliced, beef, liver, milk, needed, butter, di...</td>\n",
       "      <td>sliced beef liver milk needed butter divided v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23260</th>\n",
       "      <td>Accidental Fish</td>\n",
       "      <td>[fillet, mahi, mahi, olive, oil, salted, butte...</td>\n",
       "      <td>fillet mahi mahi olive oil salted butter garli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             name  \\\n",
       "key                                                 \n",
       "229099                   \"Instant\" Mac and Cheese   \n",
       "242352  \"Pantry Raid\" Chicken Enchilada Casserole   \n",
       "265280                  A Scotsman's Shepherd Pie   \n",
       "92761              Absolute Best Liver and Onions   \n",
       "23260                             Accidental Fish   \n",
       "\n",
       "                                               ingredient  \\\n",
       "key                                                         \n",
       "229099  [whole, milk, kosher, salt, taste, cayenne, pe...   \n",
       "242352  [tomato, sauce, water, taco, seasoning, mix, c...   \n",
       "265280  [mashed, boiled, potato, sour, cream, cream, c...   \n",
       "92761   [sliced, beef, liver, milk, needed, butter, di...   \n",
       "23260   [fillet, mahi, mahi, olive, oil, salted, butte...   \n",
       "\n",
       "                                                clean_ing  \n",
       "key                                                        \n",
       "229099  whole milk kosher salt taste cayenne pepper dr...  \n",
       "242352  tomato sauce water taco seasoning mix chili po...  \n",
       "265280  mashed boiled potato sour cream cream cheese b...  \n",
       "92761   sliced beef liver milk needed butter divided v...  \n",
       "23260   fillet mahi mahi olive oil salted butter garli...  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ing = clean_df[['ingredient', 'name']].groupby('name').agg(sum) # # condense list of ingredients to each recipe key\n",
    "X_ing['clean_ing'] = [join_strings(x) for x in X_ing['ingredient']] # joins list of strings into one string per recipe\n",
    "X_ing = X_ing.head().reset_index()\n",
    "X_ing['key'] = df.reset_index(drop=True)['key']\n",
    "X_ing = X_ing.set_index('key',drop=True)\n",
    "X_ing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "totalCal                                 2221.6\n",
       "calPerServing                             277.7\n",
       "name             Breaded Parmesan Ranch Chicken\n",
       "Name: 229099, dtype: object"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cal_train.loc[229099]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "totalCal                             2218.4\n",
       "calPerServing                        1109.2\n",
       "name             Creamy Cajun Chicken Pasta\n",
       "Name: 12009, dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cal_test.loc[12009]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>totalCal</th>\n",
       "      <th>calPerServing</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12009</th>\n",
       "      <td>2218.4</td>\n",
       "      <td>1109.2</td>\n",
       "      <td>Creamy Cajun Chicken Pasta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       totalCal  calPerServing                        name\n",
       "key                                                       \n",
       "12009    2218.4         1109.2  Creamy Cajun Chicken Pasta"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cal_test[y_cal_test['name']=='Creamy Cajun Chicken Pasta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - separate steps\n",
    "#### Bag of words vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "906\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer # Bag of Words\n",
    "bow_transformer = CountVectorizer(analyzer=text_process).fit(X_train['clean_ing'])\n",
    "print(len(bow_transformer.vocabulary_)) # Print total number of vocab words\n",
    "\n",
    "# Example bag of words on one recipe\n",
    "# bow0 = bow_transformer.transform([X_train['clean_ing'].loc[8495]])\n",
    "# print(bow0) # tells us what words appear and the frequency\n",
    "# print(bow_transformer.get_feature_names()[145]) # This tells us what the word is for a given index\n",
    "\n",
    "ingredient_bow = bow_transformer.transform(X_train['clean_ing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (688, 906)\n",
      "Amount of Non-Zero occurences:  15980\n",
      "sparsity: 2.56365829868063\n"
     ]
    }
   ],
   "source": [
    "# Bag of word counts are saved in a sparse matrix which compresses the information to save computer memory\n",
    "print('Shape of Sparse Matrix: ', ingredient_bow.shape) # matrix size (number of recipes, total number of words)\n",
    "print('Amount of Non-Zero occurences: ', ingredient_bow.nnz) \n",
    "sparsity = (100.0 * ingredient_bow.nnz / (ingredient_bow.shape[0] * ingredient_bow.shape[1]))\n",
    "print('sparsity: {}'.format(sparsity)) # total number of words / (number of recipes * total number of words)*100% compares non-zero words versus total number of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF (term frequency-inverse document frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(688, 906)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer().fit(ingredient_bow) # weight of words over whole document\n",
    "\n",
    "# Example TF-IDF on one recipe\n",
    "# tfidf0 = tfidf_transformer.transform(bow0)\n",
    "# print(tfidf0)\n",
    "\n",
    "# Transform the entire bag-of-words corpus into TF-IDF corpus at once:\n",
    "ingredient_tfidf = tfidf_transformer.transform(ingredient_bow)\n",
    "print(ingredient_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.436628982345549\n"
     ]
    }
   ],
   "source": [
    "# To see document frequency of a specific word\n",
    "print(tfidf_transformer.idf_[bow_transformer.vocabulary_['rack']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train & test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB # Naive Bayes Model\n",
    "recipe_model = MultinomialNB().fit(ingredient_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.86       685\n",
      "           1       0.02      1.00      0.04         3\n",
      "\n",
      "    accuracy                           0.76       688\n",
      "   macro avg       0.51      0.88      0.45       688\n",
      "weighted avg       1.00      0.76      0.86       688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = recipe_model.predict(ingredient_tfidf)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(predictions,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save ML model using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(ingredient_bow,open('ingredient_bow.sav','wb'))\n",
    "pickle.dump(ingredient_tfidf,open('ingredient_tfidf.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "predict not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-209-3b641b9e23fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mingredient_bow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ingredient_bow.sav'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mingredient_bow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: predict not found"
     ]
    }
   ],
   "source": [
    "ingredient_bow = pickle.load(open('ingredient_bow.sav','rb'))\n",
    "predictions = ingredient_bow.predict(X_test,y_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save BoW and TF-IDF vectorization as csv - doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "to_csv not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-ba44fa4931e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mingredient_bow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ingredient_bow.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mingredient_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ingredient_tfidf.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: to_csv not found"
     ]
    }
   ],
   "source": [
    "ingredient_bow.to_csv('ingredient_bow.csv')\n",
    "ingredient_tfidf.to_csv('ingredient_tfidf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       147\n",
      "           1       0.36      0.46      0.41        26\n",
      "\n",
      "    accuracy                           0.80       173\n",
      "   macro avg       0.63      0.66      0.64       173\n",
      "weighted avg       0.82      0.80      0.81       173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Bag of Words\n",
    "from sklearn.feature_extraction.text import TfidfTransformer # TF-IDF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "#    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', LogisticRegression()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train['clean_ing'],y_train) # Fit Model using training data\n",
    "predictions = pipeline.predict(X_test['clean_ing']) # Predict using test data\n",
    "print(predictions)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Bag of Words\n",
    "from sklearn.feature_extraction.text import TfidfTransformer # TF-IDF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', LogisticRegression()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train['clean_ing'],y_train) # Fit Model using training data\n",
    "predictions = pipeline.predict(X_test['clean_ing']) # Predict using test data\n",
    "print(predictions)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Bag of Words\n",
    "from sklearn.feature_extraction.text import TfidfTransformer # TF-IDF\n",
    "from sklearn.linear_model import LinearRegression\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "#    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', LinearRegression()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train['clean_ing'],y_cal_train) # Fit Model using training data\n",
    "predictions = pipeline.predict(X_test['clean_ing']) # Predict using test data\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "bag of words gives good precision but very bad recall\n",
    "\n",
    "TF-IDF is assigning all recipes to one label, so recall=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Bag of Words\n",
    "from sklearn.feature_extraction.text import TfidfTransformer # TF-IDF\n",
    "from sklearn.naive_bayes import MultinomialNB # Naive Bayes Model\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "#    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train['clean_ing'],y_train) # Fit Model using training data\n",
    "predictions = pipeline.predict(X_test['clean_ing']) # Predict using test data\n",
    "print(predictions)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Bag of Words\n",
    "from sklearn.feature_extraction.text import TfidfTransformer # TF-IDF\n",
    "from sklearn.naive_bayes import MultinomialNB # Naive Bayes Model\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train['clean_ing'],y_train) # Fit Model using training data\n",
    "predictions = pipeline.predict(X_test['clean_ing']) # Predict using test data\n",
    "print(predictions)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Bag of Words\n",
    "from sklearn.feature_extraction.text import TfidfTransformer # TF-IDF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "#    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', DecisionTreeClassifier()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train['clean_ing'],y_train) # Fit Model using training data\n",
    "predictions = pipeline.predict(X_test['clean_ing']) # Predict using test data\n",
    "print(predictions)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Bag of Words\n",
    "from sklearn.feature_extraction.text import TfidfTransformer # TF-IDF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', DecisionTreeClassifier()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train['clean_ing'],y_train) # Fit Model using training data\n",
    "predictions = pipeline.predict(X_test['clean_ing']) # Predict using test data\n",
    "print(predictions)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Bag of Words\n",
    "from sklearn.feature_extraction.text import TfidfTransformer # TF-IDF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "#    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', RandomForestClassifier(n_estimators=200)),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "    \n",
    "pipeline.fit(X_train['clean_ing'],y_train) # Fit Model using training data\n",
    "predictions = pipeline.predict(X_test['clean_ing']) # Predict using test data\n",
    "print(predictions)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer # Bag of Words\n",
    "from sklearn.feature_extraction.text import TfidfTransformer # TF-IDF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', RandomForestClassifier(n_estimators=200)),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "    \n",
    "pipeline.fit(X_train['clean_ing'],y_train) # Fit Model using training data\n",
    "predictions = pipeline.predict(X_test['clean_ing']) # Predict using test data\n",
    "print(predictions)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note to self:\n",
    "\n",
    "ML priority\n",
    "* Priority is to to TF-IDF on the list of words.\n",
    "* Then, add the other features (quantity, label) before doing the machine learning.\n",
    "* Then, do machine learning.\n",
    "\n",
    "Additional features\n",
    "* Make \"total calories\" as a feature (calPerServing * servings)\n",
    "* Remove/Tag certain word classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = clean_df[['ingredient', 'key']]\n",
    "X_ing = small_df.groupby('key').agg(sum)\n",
    "y_label = df.reset_index(drop=True)['label']\n",
    "X_keys = df.reset_index(drop=True)['recipe_key']\n",
    "\n",
    "# IF need to sum integer values per key\n",
    "clean_df.groupby('key').agg({'b': 'sum', 'c': lambda x: ' '.join(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flattens list of list into one list. but lose the recipe key\n",
    "# [val for sublist in X_ing['ingredient'] for val in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_df.index.get_level_values(0) # now this is a multilevel index / hierarchical dataframe\n",
    "\n",
    "# This is how to select row of a multilevel index: df.loc[recipe_key, ingredient_key]\n",
    "clean_df.loc[229099,0]\n",
    "# Data Exploration\n",
    "# Look at what units are used for a specific ingredients\n",
    "clean_df[clean_df['ingredient']=='water']['unit'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit normalization - work in progress...\n",
    "\n",
    "Currently have the common units normalized to ml or grams (assuming 1 mL = 1 g).\n",
    "\n",
    "If have time, assign an integer value to the specific units in the dictionary, instead of pulling out first word of the ingredient string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Histogram of unit count\n",
    "from collections import Counter\n",
    "letter_counts = Counter(clean_df['unit'])\n",
    "count = pd.DataFrame.from_dict(letter_counts, orient='index')\n",
    "count = count.sort_values(by=[0], ascending=False)\n",
    "\n",
    "count[0:60].plot(kind='bar',figsize=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df[clean_df['unit']=='boneless']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean text -  work in progress ...\n",
    "\n",
    "1) For ingredients that got replaced with the \"unit\"value, need to replace the \"unit\" value as unit.\n",
    "if ingredient[row]=nan, then ingredient[row]=unit[row], and unit[row]='unit'\n",
    "* DON'T NEED TO DO THIS ANYMORE\n",
    "\n",
    "2) Remove plural words using stemmer instead of wnl.lemmatize (ex. lammantize function doesnt change children to child)\n",
    "\n",
    "3) Fix parse_text to improve removal of non-word punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['calPerServing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(df[df['servings']==4]['calPerServing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['num_ingredients'])\n",
    "sns.distplot(df['servings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['servings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='num_ingredients', y='calPerServing', data=clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='servings', y='calPerServing', data=clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='servings', y='num_ingredients', data=clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
